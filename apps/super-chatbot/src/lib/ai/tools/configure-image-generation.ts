import { tool } from "ai";
import { z } from "zod";
import type { MediaOption } from "@/lib/types/media-settings";
import {
  checkBalanceBeforeArtifact,
  getOperationDisplayName,
} from "@/lib/utils/ai-tools-balance";
import type { Session } from "next-auth";
import { analyzeImageContext } from "@/lib/ai/context";

interface CreateImageDocumentParams {
  createDocument: any;
  session?: Session | null;
  defaultSourceImageUrl?: string | undefined;
  chatId?: string;
  userMessage?: string;
  currentAttachments?: any[];
}

export const configureImageGeneration = (params?: CreateImageDocumentParams) =>
  tool({
    description:
      "Configure image generation settings or generate an image directly if prompt is provided. Supports text-to-image by default, and image-to-image when a sourceImageUrl is provided. When triggered, creates an image artifact that shows generation progress in real-time.",
    inputSchema: z.object({
      prompt: z
        .string()
        .optional()
        .describe(
          "Detailed description of the image to generate. If provided, will immediately create image artifact and start generation"
        ),
      sourceImageUrl: z
        .string()
        .url()
        .optional()
        .describe(
          "Optional source image URL for image-to-image generation (e.g., when the user uploaded an image in chat). If provided, the system will run image-to-image."
        ),
      style: z
        .string()
        .optional()
        .describe(
          'Style of the image. Supports many formats: "realistic", "cinematic", "anime", "cartoon", "sketch", "painting", "steampunk", "fantasy", "sci-fi", "horror", "minimalist", "abstract", "portrait", "landscape", and many more available styles'
        ),
      resolution: z
        .string()
        .optional()
        .describe(
          'Image resolution. Accepts various formats: "1920x1080", "1920Ã—1080", "1920 x 1080", "full hd", "fhd", "1080p", "square", "vertical", "horizontal", etc.'
        ),
      shotSize: z
        .string()
        .optional()
        .describe(
          'Shot size/camera angle. Accepts: "close-up", "medium-shot", "long-shot", "extreme-close-up", "portrait", "two-shot", etc.'
        ),
      model: z
        .string()
        .optional()
        .describe(
          'AI model to use. Models are loaded dynamically from SuperDuperAI API. Use model name like "FLUX" or full model ID.'
        ),
      seed: z.number().optional().describe("Seed for reproducible results"),
      batchSize: z
        .number()
        .min(1)
        .max(3)
        .optional()
        .describe(
          "Number of images to generate simultaneously (1-3). Higher batch sizes generate multiple variations at once."
        ),
    }),
    execute: async ({
      prompt,
      sourceImageUrl,
      style,
      resolution,
      shotSize,
      model,
      seed,
      batchSize,
    }) => {
      console.log("ðŸ”§ configureImageGeneration called with:", {
        prompt,
        style,
        resolution,
        shotSize,
        model,
        seed,
        batchSize,
      });

      // AICODE-NOTE: Define Nano Banana constants at the top of execute function
      const NANO_BANANA_STYLES = [
        { id: "realistic", label: "Realistic", description: "Photorealistic images" },
        { id: "cinematic", label: "Cinematic", description: "Cinematic style with dramatic lighting" },
        { id: "anime", label: "Anime", description: "Japanese animation style" },
        { id: "cartoon", label: "Cartoon", description: "Cartoon style" },
        { id: "chibi", label: "Chibi", description: "Miniature cute style" },
        { id: "3d-render", label: "3D Render", description: "Three-dimensional computer graphics" },
        { id: "oil-painting", label: "Oil Painting", description: "Classic oil painting" },
        { id: "watercolor", label: "Watercolor", description: "Gentle watercolor technique" },
        { id: "sketch", label: "Sketch", description: "Pencil sketch" },
        { id: "digital-art", label: "Digital Art", description: "Modern digital creativity" },
      ];

      const NANO_BANANA_QUALITY_LEVELS = [
        { id: "standard", label: "Standard", multiplier: 1.0, description: "Base quality" },
        { id: "high", label: "High", multiplier: 1.5, description: "Enhanced quality" },
        { id: "ultra", label: "Ultra", multiplier: 2.0, description: "Maximum quality" },
      ];

      const NANO_BANANA_ASPECT_RATIOS = [
        { id: "1:1", label: "Square (1:1)", width: 1024, height: 1024 },
        { id: "16:9", label: "Widescreen (16:9)", width: 1920, height: 1080 },
        { id: "9:16", label: "Vertical (9:16)", width: 768, height: 1366 },
        { id: "4:3", label: "Classic (4:3)", width: 1024, height: 768 },
      ];

      // If no prompt provided, return Nano Banana configuration panel
      if (!prompt) {
        console.log(
          "ðŸŒ No prompt provided, returning Nano Banana configuration panel"
        );
        return {
          model: "gemini-2.5-flash-image",
          provider: "nano-banana",
          availableStyles: NANO_BANANA_STYLES,
          availableQualityLevels: NANO_BANANA_QUALITY_LEVELS,
          availableAspectRatios: NANO_BANANA_ASPECT_RATIOS,
          capabilities: [
            "Context-aware editing",
            "Surgical precision",
            "Understanding physical logic",
            "Intelligent lighting",
            "Multimodal inputs",
            "Creative partnership",
          ],
        };
      }

      console.log("ðŸŒ âœ… PROMPT PROVIDED, GENERATING WITH NANO BANANA:", prompt);

      // Check style for quality multipliers
      const multipliers: string[] = [];
      if (style?.includes("high-quality")) multipliers.push("high-quality");
      if (style?.includes("ultra-quality")) multipliers.push("ultra-quality");

      try {
        // Map old resolution format to Nano Banana aspect ratio
        const foundAspectRatio = resolution
          ? NANO_BANANA_ASPECT_RATIOS.find((r) => r.label.includes(resolution) || resolution.includes(r.id))
          : null;
        const selectedAspectRatio = (foundAspectRatio || NANO_BANANA_ASPECT_RATIOS[0])!; // Always has value from array

        // Map old style to Nano Banana style
        const foundStyle = style
          ? NANO_BANANA_STYLES.find((s) => s.label.toLowerCase().includes(style.toLowerCase()) || style.toLowerCase().includes(s.label.toLowerCase()))
          : null;
        const selectedStyle = (foundStyle || NANO_BANANA_STYLES[0])!; // Always has value from array

        // Use high quality by default
        const selectedQuality = NANO_BANANA_QUALITY_LEVELS[1]!; // "high" - Always has value from array

        // Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð½Ð¾Ð²ÑƒÑŽ ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°
        let normalizedSourceUrl = sourceImageUrl;

        console.log("ðŸ” configureImageGeneration sourceImageUrl resolution:", {
          sourceImageUrl,
          defaultSourceImageUrl: params?.defaultSourceImageUrl,
          chatId: params?.chatId,
          userMessage: params?.userMessage,
        });

        // ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚ 1: defaultSourceImageUrl (legacy Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ°)
        if (
          params?.defaultSourceImageUrl &&
          /^https?:\/\//.test(params.defaultSourceImageUrl)
        ) {
          console.log(
            "ðŸ” Using defaultSourceImageUrl from legacy context analysis:",
            params.defaultSourceImageUrl
          );
          normalizedSourceUrl = params.defaultSourceImageUrl;
        }
        // ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚ 2: Ð½Ð¾Ð²Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°
        else if (params?.chatId && params?.userMessage) {
          try {
            console.log("ðŸ” Analyzing image context with new system...");
            const contextResult = await analyzeImageContext(
              params.userMessage,
              params.chatId,
              params.currentAttachments,
              params.session?.user?.id
            );

            console.log("ðŸ” Context analysis result:", contextResult);

            if (contextResult.sourceUrl && contextResult.confidence !== "low") {
              console.log(
                "ðŸ” Using sourceUrl from new context analysis:",
                contextResult.sourceUrl,
                "confidence:",
                contextResult.confidence
              );
              normalizedSourceUrl = contextResult.sourceUrl;
            }
          } catch (error) {
            console.warn("ðŸ” Error in context analysis, falling back:", error);
          }
        }
        // ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚ 3: AI-provided sourceImageUrl
        else if (
          normalizedSourceUrl &&
          /^https?:\/\//.test(normalizedSourceUrl) &&
          !normalizedSourceUrl.startsWith("attachment://")
        ) {
          console.log(
            "ðŸ” Using AI-provided sourceImageUrl:",
            normalizedSourceUrl
          );
        }
        // Fallback: text-to-image
        else {
          console.log(
            "ðŸ” No valid source image URL available, will be text-to-image"
          );
          normalizedSourceUrl = undefined;
        }

        // Determine operation type and check balance
        const operationType = normalizedSourceUrl
          ? "image-to-image"
          : "text-to-image";

        // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ð±Ñ‹Ð» Ð»Ð¸ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ð¹ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð»Ñ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°
        if (
          params?.userMessage &&
          normalizedSourceUrl &&
          operationType === "image-to-image"
        ) {
          // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ð»Ð¸ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð½Ð° Ð¿Ð¾Ð¸ÑÐº Ð¿Ð¾ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ð¼Ñƒ
          const semanticSearchPatterns = [
            /(ÐºÐ°Ñ€Ñ‚Ð¸Ð½Ðº[Ð°-Ñ]+\s+Ñ\s+|Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ\s+Ñ\s+|Ñ„Ð¾Ñ‚Ð¾\s+Ñ\s+|image\s+with\s+|picture\s+with\s+|photo\s+with\s+)/i,
            /(ÐºÐ°Ñ€Ñ‚Ð¸Ð½Ðº[Ð°-Ñ]+\s+Ð³Ð´Ðµ\s+ÐµÑÑ‚ÑŒ|Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ\s+Ð³Ð´Ðµ\s+ÐµÑÑ‚ÑŒ|Ñ„Ð¾Ñ‚Ð¾\s+Ð³Ð´Ðµ\s+ÐµÑÑ‚ÑŒ|image\s+that\s+has|picture\s+that\s+contains|photo\s+that\s+shows)/i,
          ];

          const hasSemanticSearchRequest = semanticSearchPatterns.some(
            (pattern) => pattern.test(params.userMessage || "")
          );

          if (hasSemanticSearchRequest) {
            // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ð±Ñ‹Ð» Ð»Ð¸ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ð¹ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ñ‡ÐµÑ€ÐµÐ· ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ð¸ÑÐº
            // Ð•ÑÐ»Ð¸ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð±Ñ‹Ð» Ð½Ð°Ð¹Ð´ÐµÐ½ Ñ‡ÐµÑ€ÐµÐ· fallback (Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ), ÑÑ‚Ð¾ Ð¾Ð·Ð½Ð°Ñ‡Ð°ÐµÑ‚, Ñ‡Ñ‚Ð¾ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ð¸ÑÐº Ð½Ðµ ÑÑ€Ð°Ð±Ð¾Ñ‚Ð°Ð»
            const isFallbackSource =
              params.defaultSourceImageUrl === normalizedSourceUrl;

            console.log("ðŸ” Fallback check:", {
              normalizedSourceUrl,
              defaultSourceImageUrl: params.defaultSourceImageUrl,
              isFallbackSource,
              hasSemanticSearchRequest,
            });

            if (isFallbackSource) {
              console.log(
                "ðŸ” Semantic search failed, providing helpful message instead of balance error"
              );
              return {
                error: "semantic_search_failed",
                message:
                  "Ðš ÑÐ¾Ð¶Ð°Ð»ÐµÐ½Ð¸ÑŽ, Ñ Ð½Ðµ ÑÐ¼Ð¾Ð³ Ð½Ð°Ð¹Ñ‚Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ñ Ð½ÑƒÐ¶Ð½Ñ‹Ð¼ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ñ‹Ð¼ Ð² Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ñ‡Ð°Ñ‚Ð°. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ:\n\nâ€¢ Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð½Ð¾Ð²Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ñ Ð½ÑƒÐ¶Ð½Ñ‹Ð¼ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ñ‹Ð¼\nâ€¢ ÐžÐ¿Ð¸ÑÐ°Ñ‚ÑŒ ÑÑ†ÐµÐ½Ñƒ Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ\nâ€¢ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð±Ð¾Ð»ÐµÐµ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, 'Ð¿ÐµÑ€Ð²Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ' Ð¸Ð»Ð¸ 'Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ')",
                suggestions: [
                  "Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ñ Ð»ÑƒÐ½Ð¾Ð¹",
                  "Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð½Ð¾Ð²Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ñ Ð»ÑƒÐ½Ð¾Ð¹",
                  "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ",
                  "ÐžÐ¿Ð¸ÑÐ°Ñ‚ÑŒ ÑÑ†ÐµÐ½Ñƒ Ð´Ð»Ñ Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ",
                ],
              };
            }
          }
        }

        const balanceCheck = await checkBalanceBeforeArtifact(
          params?.session || null,
          "image-generation",
          operationType,
          multipliers,
          getOperationDisplayName(operationType)
        );

        if (!balanceCheck.valid) {
          console.log("ðŸ”§ âŒ INSUFFICIENT BALANCE, NOT CREATING ARTIFACT");
          return {
            error:
              balanceCheck.userMessage ||
              "Insufficient funds for image generation",
            balanceError: true,
            requiredCredits: balanceCheck.cost,
          };
        }

        // AICODE-NOTE: Use Nano Banana provider directly instead of old SuperDuperAI artifact system
        console.log("ðŸŒ âœ… USING NANO BANANA PROVIDER FOR IMAGE GENERATION");

        // Create prompt for Nano Banana
        let nanoBananaPrompt = prompt;

        // Add style instructions
        if (selectedStyle.id !== "realistic") {
          nanoBananaPrompt += `, ${selectedStyle.description.toLowerCase()}`;
        }

        // Add quality instructions
        if (selectedQuality.id !== "standard") {
          nanoBananaPrompt += `, ${selectedQuality.description.toLowerCase()}`;
        }

        // Add aspect ratio instructions
        nanoBananaPrompt += `, ${selectedAspectRatio.label.toLowerCase()}`;

        console.log("ðŸŒ Final Nano Banana prompt:", nanoBananaPrompt);

        try {
          // Use Nano Banana Provider (Gemini API)
          const { nanoBananaProvider } = await import("../providers/nano-banana");

          const nanoBananaParams = {
            prompt: nanoBananaPrompt,
            ...(normalizedSourceUrl && { sourceImageUrl: normalizedSourceUrl }),
            style: selectedStyle.id,
            quality: selectedQuality.id,
            aspectRatio: selectedAspectRatio.id,
            ...(seed && { seed }),
            nanoBananaFeatures: {
              enableContextAwareness: true,
              enableSurgicalPrecision: true,
              creativeMode: false,
            },
          };

          const result = await nanoBananaProvider.generateImage(nanoBananaParams);

          console.log("ðŸŒ âœ… NANO BANANA API RESULT:", result);

          return {
            ...result,
            message: `Image generated successfully using Nano Banana (Gemini 2.5 Flash Image): "${prompt}". Style: ${selectedStyle.label}, Quality: ${selectedQuality.label}, Format: ${selectedAspectRatio.label}.`,
            nanoBananaInfo: {
              model: "gemini-2.5-flash-image",
              capabilities: [
                "Context-aware editing",
                "Surgical precision",
                "Physical logic understanding",
                "Intelligent lighting",
              ],
              style: selectedStyle,
              quality: selectedQuality,
              aspectRatio: selectedAspectRatio,
            },
          };
        } catch (error) {
          console.error("ðŸŒ âŒ NANO BANANA ERROR:", error);
          throw error;
        }
      } catch (error: any) {
        console.error("ðŸ”§ âŒ ERROR IN IMAGE GENERATION:", error);
        return {
          error: `Failed to generate image: ${error.message}`,
          message: `Unfortunately, image generation failed: "${prompt}". Error: ${error.message}`,
        };
      }
    },
  });

// Helper function to find style (kept for backward compatibility)
export function findStyle(
  styleName: string,
  availableStyles: MediaOption[]
): MediaOption | null {
  const normalizedStyleName = styleName.toLowerCase().trim();

  // Direct match by label or id
  let foundStyle = availableStyles.find(
    (style) =>
      style.label.toLowerCase() === normalizedStyleName ||
      style.id.toLowerCase() === normalizedStyleName
  );

  if (foundStyle) return foundStyle;

  // Partial match
  foundStyle = availableStyles.find(
    (style) =>
      style.label.toLowerCase().includes(normalizedStyleName) ||
      style.id.toLowerCase().includes(normalizedStyleName) ||
      normalizedStyleName.includes(style.label.toLowerCase()) ||
      normalizedStyleName.includes(style.id.toLowerCase())
  );

  return foundStyle || null;
}
