import type { IGenerationConfigRead } from '@turbo-super/api';
import {
  getAvailableVideoModels,
  getAvailableImageModels,
  configureSuperduperAI,
} from '../../../lib/config/superduperai';
import type {
  ImageGenerationConfig,
  VideoGenerationConfig,
} from '../../../lib/types/media-settings';

// Adapter function to convert OpenAPI model to MediaSettings format
function adaptModelForMediaSettings(
  model: IGenerationConfigRead,
): IGenerationConfigRead & {
  id: string;
  description: string;
  value: string;
  workflowPath: string;
  price: number;
  label: string;
} {
  return {
    ...model,
    id: model.name, // Use name as id for compatibility
    label: model.label || model.name || 'Unknown Model', // Ensure label is always a string
    description: `${model.type} - ${model.source}`,
    value: model.name,
    workflowPath: model.params?.workflow_path || '',
    price: model.params?.price || 0,
  };
}

async function testMediaSettingsWithOpenAPI() {
  console.log('üé® MediaSettings OpenAPI Integration Test');
  console.log('==================================================');

  try {
    // Configure client
    configureSuperduperAI();

    // Test image models integration
    console.log('\nüñºÔ∏è  Testing Image Models Integration...');
    const imageModels = await getAvailableImageModels();
    console.log(`‚úÖ Loaded ${imageModels.length} image models`);

    // Create mock ImageGenerationConfig with OpenAPI models
    const adaptedImageModels = imageModels.map(adaptModelForMediaSettings);
    const imageConfig: ImageGenerationConfig = {
      type: 'image-generation-settings',
      availableModels: adaptedImageModels,
      availableResolutions: [
        { width: 1024, height: 1024, label: '1024x1024', aspectRatio: '1:1' },
        { width: 1024, height: 768, label: '1024x768', aspectRatio: '4:3' },
        { width: 768, height: 1024, label: '768x1024', aspectRatio: '3:4' },
      ],
      availableStyles: [
        {
          id: 'realistic',
          label: 'Realistic',
          description: 'Photorealistic style',
        },
        {
          id: 'artistic',
          label: 'Artistic',
          description: 'Artistic interpretation',
        },
      ],
      availableShotSizes: [
        { id: 'close-up', label: 'Close-up', description: 'Close-up shot' },
        { id: 'medium_shot', label: 'Medium', description: 'Medium shot' },
      ],
      defaultSettings: {
        resolution: {
          width: 1024,
          height: 1024,
          label: '1024x1024',
          aspectRatio: '1:1',
        },
        style: {
          id: 'realistic',
          label: 'Realistic',
          description: 'Photorealistic style',
        },
        shotSize: {
          id: 'medium_shot',
          label: 'Medium Shot',
          description: 'Medium shot',
        },
        model: adaptedImageModels[0] || {
          name: 'fallback',
          label: 'Fallback Model',
          type: 'text_to_image' as any,
          source: 'local' as any,
          params: {},
          id: 'fallback',
          description: 'Fallback model',
          value: 'fallback',
          workflowPath: '',
          price: 0,
        },
      },
    };

    console.log(
      '‚úÖ Image config created with models:',
      imageConfig.availableModels.map((m) => m.name),
    );

    // Test video models integration
    console.log('\nüé¨ Testing Video Models Integration...');
    const videoModels = await getAvailableVideoModels();
    console.log(`‚úÖ Loaded ${videoModels.length} video models`);

    // Create mock VideoGenerationConfig with OpenAPI models
    const adaptedVideoModels = videoModels.map(adaptModelForMediaSettings);
    const videoConfig: VideoGenerationConfig = {
      type: 'video-generation-settings',
      availableModels: adaptedVideoModels,
      availableDurations: [
        { value: 10, label: '10 seconds', id: '10s' },
        { value: 20, label: '20 seconds', id: '20s' },
      ],
      availableResolutions: [
        {
          width: 1280,
          height: 720,
          label: '1280x720 (HD)',
          aspectRatio: '16:9',
        },
        {
          width: 1920,
          height: 1080,
          label: '1920x1080 (Full HD)',
          aspectRatio: '16:9',
        },
      ],
      availableStyles: [
        {
          id: 'cinematic',
          label: 'Cinematic',
          description: 'Movie-like style',
        },
        {
          id: 'documentary',
          label: 'Documentary',
          description: 'Documentary style',
        },
      ],
      availableShotSizes: [
        {
          id: 'wide',
          label: 'Wide Shot',
          description: 'Wide establishing shot',
        },
        { id: 'close-up', label: 'Close-up', description: 'Close-up shot' },
      ],
      availableFrameRates: [
        { value: 24, label: '24 FPS (Cinematic)' },
        { value: 30, label: '30 FPS (Standard)' },
      ],
      defaultSettings: {
        resolution: {
          width: 1280,
          height: 720,
          label: '1280x720 (HD)',
          aspectRatio: '16:9',
        },
        style: {
          id: 'cinematic',
          label: 'Cinematic',
          description: 'Movie-like style',
        },
        shotSize: {
          id: 'wide',
          label: 'Wide Shot',
          description: 'Wide establishing shot',
        },
        model: adaptedVideoModels[0] || {
          name: 'fallback',
          label: 'Fallback Model',
          type: 'text_to_video' as any,
          source: 'local' as any,
          params: {},
          id: 'fallback',
          description: 'Fallback model',
          value: 'fallback',
          workflowPath: '',
          price: 0,
        },
        frameRate: 30,
        duration: { value: 10, label: '10 seconds', id: '10s' },
        negativePrompt: '',
      },
    };

    console.log(
      '‚úÖ Video config created with models:',
      videoConfig.availableModels.map((m) => m.name),
    );

    // Test type compatibility
    console.log('\nüîç Testing Type Compatibility...');

    // Check if OpenAPI models are compatible with MediaSettings expectations
    const imageModelSample = imageConfig.availableModels[0];
    const videoModelSample = videoConfig.availableModels[0];

    console.log('üìã Image model sample:', {
      name: imageModelSample?.name,
      type: imageModelSample?.type,
      source: imageModelSample?.source,
      hasRequiredFields: !!imageModelSample?.name,
    });

    console.log('üìã Video model sample:', {
      name: videoModelSample?.name,
      type: videoModelSample?.type,
      source: videoModelSample?.source,
      hasRequiredFields: !!videoModelSample?.name,
    });

    // Test model filtering by type
    const textToImageModels = imageModels.filter(
      (m) => m.type === 'text_to_image',
    );
    const imageToImageModels = imageModels.filter(
      (m) => m.type === 'image_to_image',
    );
    const textToVideoModels = videoModels.filter(
      (m) => m.type === 'text_to_video',
    );
    const imageToVideoModels = videoModels.filter(
      (m) => m.type === 'image_to_video',
    );

    console.log('\nüìä Model Type Distribution:');
    console.log(`  Text-to-Image: ${textToImageModels.length}`);
    console.log(`  Image-to-Image: ${imageToImageModels.length}`);
    console.log(`  Text-to-Video: ${textToVideoModels.length}`);
    console.log(`  Image-to-Video: ${imageToVideoModels.length}`);

    console.log(
      '\n‚úÖ MediaSettings OpenAPI integration test completed successfully!',
    );
    console.log('üéØ Ready for MediaSettings component migration');
  } catch (error) {
    console.error('‚ùå Test failed:', error);
    process.exit(1);
  }
}

testMediaSettingsWithOpenAPI();
